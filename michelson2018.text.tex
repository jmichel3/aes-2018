% Template for 61st conference for non-peer-reviewed articled
\documentclass[convention,peer-reviewed]{aesconf}

% Graphics path
\graphicspath{{./}{figs/}}

% UTF-8 encoding is recommended but use one that works for you.
\usepackage[utf8]{inputenc}

% Highly recommended package for better looking text automatically.
\usepackage{microtype}

% Natbib is used for more control on citations. You can use other moderd
% bibliography packages but please try to match the provided style.
\usepackage[numbers,square]{natbib} 


% These are useful for different purposes.
\usepackage{color}
\usepackage{url}
\usepackage{colortbl}
\usepackage{graphicx}
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{setspace}
\usepackage{subfigure}
\usepackage{svg}

% The full title of the paper
\title{Automatic Guitar Tablature Transcription from Audio using Inharmonicity Regressions
and Bayesian Classification}

% Put the authors in order here. The number in brackets define the corresponding affiliation.
\author[1]{Jonathan Michelson}
\author[2]{Richard Stern}
\author[2]{Thomas Sullivan}

% Affiliations go here
\affil[1]{New Sensor Corporation / Electro-Harmonix}
\affil[2]{Carnegie Mellon University}

% Correspondece should include the corresponding author's name and e-mail address
\correspondence{Jonathan Michelson}{jonathan@ehx.com}

% These are used for headers. Anything that fits is okay. Please use proper punctuation.

% If there are many authors, please use the form "First author et al."
\lastnames{Michelson et al.}

% Short title should describe your topic but not be too long.
\shorttitle{Tablature Transcription using Inharmonicity Regressions}


% This is required and draws the top title
\include{aestitle}

\begin{document}

\setlength{\parindent}{1em}

\twocolumn[
\maketitle % MANDATORY! 

\begin{onecolabstract}
We propose two new methods to classify guitar strings using only audio with the goal of developing automated tablature transcription. The first method regresses the log-inharmonicities of guitar strings against their pitches to obtain characteristic linear trajectories, and assigns unseen notes to the strings of the regressions whose means and variances maximize the probability of the measured inharmonicities of the notes. The second method, developed as a baseline against which to measure the first, characterizes the inharmonicity distribution of each fretboard position as a normal probability density, then similarly assigns unseen notes to the fretboard positions that maximize the likelihood of their observed inharmonicities. Results from the standard Real World Corpus of guitar recordings show that exploiting log-inharmonicity regressions generally increases performance compared to our Bayesian method, but does not generally increase performance on classical and acoustic guitars compared to an existing inharmonicity-based system in \citet{barbanchoi2012}.
\end{onecolabstract}
]

\section{Introduction}
The guitar is a popular musical instrument whose family comprises a diverse collection of stringed instruments. Despite their variation, the majority of guitar configurations exhibit six strings tuned to $E2$ ($82$ Hz), $A2$ ($110$ Hz), $D3$ ($147$ Hz), $G3$ ($196$ Hz), $B3$ ($247$ Hz), and $E4$ ($330$ Hz). Most guitars also typically have upwards of 20 frets, allowing for versatile musical passage realizations along the fretboard. A consequence of the tuning and extensive fretting locations is liberal pitch overlap between neighboring strings; multiple fretboard locations can usually be selected to produce a given pitch. This ambiguity renders conventional music scores, which represent passages as notes and chords, undesirable for students trying to learn more skillful placement of scales and arpeggios, or for enthusiasts trying to uncover the fretboard positions used on riffs recorded by virtuosic players. Figure~\ref{fig:score-tabs} illustrates this ambiguity.

Tablature is a desirable alternative music notation that does not suffer from the one-to-many mapping of scores. The staff, instead of representing pitch as in classical notation, depicts a birds-eye view of the guitar neck from the perspective of the performer. Each of the six horizontal lines signify a corresponding string on the guitar, and numbers on each line specify the fret to be fingered. Reasons for tablature desirability are numerous \citep{macrae2010}, such as accessibility (legibility does not require formal musical training) and transportability (tablature can be easily represented with ASCII characters). 

Accurate tablature transcription is a laborious task, however. Dependable tablature containing few errors typically require the careful listening of a seasoned musician to an audio recording, and possibly video recordings for additional consultation. Reliable automation of this transcription task would benefit the guitar student community by expediting quality tablature generation and unearthing fretboard positions of guitar riffs in songs for which accurate tablature does not yet exist.
\begin{figure}[!htbp] 
\centering
\includegraphics[scale=0.2]{figs/score-tabs}
\caption{Musical score and two identical realizations of that score in tablature notation. Figure taken from \citep{barbanchoi2012}.}
\label{fig:score-tabs}
\end{figure}

An important feature in systems that transcribe tablature from audio input is inharmonicity. When an ideal string fixed at both ends is displaced, the restoring force that causes it to oscillate is its tension. For a real string with stiffness, however, its elasticity contributes to this restoring force \citep{fletcher1962}, causing the frequencies of the modes of vibration to deviate from integer multiples of the fundamental. Instead, the solutions to the one-dimensional wave equation become: 
\begin{equation}
\label{eq:fk}
f_k = kf_{0}\sqrt{1+\beta k^2}
\end{equation}
where $f_k$ is the $k$th harmonic of fundamental $f_0$ and $\beta$ is the inharmonicity of the string, defined by
\begin{equation}
\beta = \frac{\pi^3 Q d^4}{64 T l^2}. \label{eq:beta}
\end{equation}
In other words, the inharmonicity $\beta$ of a vibrating string is a dimensionless quantity that depends on the Young's modulus $Q$, diameter $d$, tension $T$, and vibrating length $l$ of the string, and which skews the $k$th partial of the string upwards in frequency according to equation~(\ref{eq:fk}). See Figure~\ref{fig:skew}. 

\begin{figure}[!htbp]
\centering
\includegraphics[scale=0.3]{skew}
\caption{Power spectrum of note D2 plucked on an electric guitar at string 5 and fret 5. Red dashed lines are drawn at integer multiples of the fundamental. The partial peaks begin visibly skewing rightward after the fifth harmonic.}
\label{fig:skew}
\end{figure}

Moreover, inharmonicity in the guitar varies in a deterministic manner with respect to fret positions along a given string. Specifically, the inharmonicity $\beta(s,n)$ of a note produced by string $s$ at fret number $n$ can be expressed in terms of the inharmonicity of the open-string note $\beta(s,0)$ according to:
\begin{equation} 
\label{eq:beta-traj}
\beta(s,n) = \beta(s,0)2^{\frac{n}{6}}
\end{equation}
Figure~\ref{fig:beta-trajectories-ag} illustrates these theoretical trajectories, which have been successfully leveraged in an existing transcription system \citep{barbanchoi2012}.

\begin{figure}[h] 
\centering
\includegraphics[scale=0.25]{figs/beta-trajectories-ag}
\caption{Example inharmonicity trajectories of acoustic guitar strings, calculated from measured open-string inharmonicities. Only Fret 0 (open-string) through Fret 3 are shown.}
\label{fig:beta-trajectories-ag}
\end{figure}

Exploiting the \textit{empirical} trajectories of guitar strings, however, has not yet been investigated. If the notes along a guitar neck are sufficiently sampled, it is plausible that capturing the empirical inharmonicity trend could reduce transcription errors by suppressing noise in the inharmonicity-estimation routine. Furthermore, if a sufficiently diverse set of guitars is sampled, the empirical trajectories may improve system generalizability. We therefore propose to classify unseen notes as belonging to the string whose pre-computed log-inharmonicity regression most probably predicts the estimated log-inharmonicity of the note. To contextualize its performance as well as that of its predecessor, we also introduce a baseline Bayesian classifier of fretboard position given an unseen note: the measured inharmonicities of each fretboard position are collected and fit to a normal distribution, and are used to return the string that maximizes the probability of having observed the measured inharmonicity of the unseen note.

\section{Previous Work}

Empirical estimation of inharmonicity has been investigated for nearly 40 years. Using pitch extraction techniques to perform estimation was first attempted by Galembo in 1979 and 1986 \citep{galembo1979,galembo1987}. In 1994, Galembo \citep{galembo1994} hypothesized a connection between partials-based fundamental pitch estimates and the degree of inharmonicity in a spectrum. The same authors in \citep{galembo1999} introduced another method in 1999 based on inharmonic comb filters. Rauhala \citep{rauhala2007} introduced an efficient iterative procedure in 2007, known as partial frequency deviations (PFD). In 2009, Hodgkinson \citep{hodgkinson2009} proposed a yet more efficient and accurate algorithm, named median-adjustive trajectories (MAT). Three years later, Barbancho \citep{barbanchoi2012} introduced another PFD-based approach, which we refer to as the partial coincidence tally (PCT) method, as part of a guitar tablature transcription system. Also in 2012, Abesser \citep{abesser2012} used parametric spectral modeling, again in the context of a guitar tablature transcription system.

Inharmonicity-based tablature transcription has also received ample study. A number of teams have had success with machine learning techniques such as neural networks, genetic algorithms, hidden Markov models, and SVMs  \citep{gagnon2003,tuohy2006,barbancho2009,barbanchoa2012,abesser2012,kehling2014,dittmar2013,abesser2012}.

\section{Methods}

\subsection{Inharmonicity Regression}
\label{sub:inharmonicity-regression}
First, we estimate the inharmonicity of an unseen note. The algorithm we employ is the median adjustive trajectories (MAT) method \citep{hodgkinson2009} proposed by Hodgkinson in 2009. The MAT algorithm was chosen for its efficiency and accuracy over the algorithms that preceded it \citep{hodgkinson2009}. We apply this estimation procedure to five Hann-windowed audio segments of length $2^{14}$ samples, beginning at the detected onset of a note and at four successive 100-ms intervals (i.e. 0 ms, 100 ms, 200 ms, 300 ms, and 400 ms after the note onset). This yields five inharmonicity estimates we later compile into one classification result using the frame aggregation refinement technique in \citep{abesser2012}.

Next, we apply a log transformation to the estimated inharmonicities to make their variation linear with respect to MIDI pitch. If we reconsider equation~\eqref{eq:beta-traj} in terms of MIDI pitch number $m$ instead of fret number $n$, we obtain
\begin{equation}
\beta(s,m) = \beta(s,m_{os})2^{\frac{m-m_{os}}{6}},
\end{equation}
where $m_{os}$ is the open-string pitch of string $s$. Figure~\ref{fig:beta-v-midi} illustrates the trajectories in terms of MIDI pitches.
\begin{figure}[h] 
\centering
\includegraphics[scale=0.25]{beta-v-midi}
\caption{Inharmonicity estimates for Frets 0-12 on Strings 1-6 of RWC Acoustic Guitar AG111, plotted against MIDI fundamental instead of fret number.}
\label{fig:beta-v-midi}
\end{figure}
Now if we consider the log-inharmonicity $\beta_{l}(m)$, we see that
\begin{equation}
\beta_l(m) = \log_2\beta(s,m) = \log_2[\beta(m_{os})2^{\frac{m-m_{os}}{6}}]
\end{equation}
\begin{equation}
\beta_l(m) = \log_2\beta(m_{os}) + \frac{m-m_{os}}{6}
\end{equation}
\begin{equation}
\beta_l(m) = (\log_2\beta(m_{os})-\frac{m_{os}}{6}) + (\frac{1}{6})m,
\end{equation}
where string $s$ has been dropped from the notation since we're looking only at variation along a fixed string. Substituting $w_0$ for $\log_2\beta(m_{os})-\frac{m_{os}}{6}$ and letting $w_1 = \frac{1}{6}$, we obtain the standar linear form
\begin{equation}
\label{eq:linear-traj}
\beta_l(m) = w_0 + w_1m,
\end{equation}
showing us that the log-inharmonicity trajectory of a given string varies linearly with respect to both MIDI pitch and fret number. See Figure~\ref{fig:log-beta-v-midi}.
\begin{figure}[!htbp] 
\centering
\includegraphics[scale=0.25]{log-beta-v-midi}
%\includesvg{figs/log-beta-v-midi}
\caption{Log-inharmonicity estimates for same frets, strings, and guitar as Fig.~\ref{fig:beta-v-midi}.}
\label{fig:log-beta-v-midi}
\end{figure}

We next use linear regressions to obtain empirical log-inharmonicity trajectories. We collect all notes with common string labels in our training data, and we perform linear regression of their log-inharmonicities $\beta$ against their fundamental pitches $m$ (in MIDI note number format). We do this for each string label. Let $s \in \{1,2,3,4,5,6\}$ be the string label to which each training note is assigned, and $N_s$ be the number of notes we have belonging to string label $s$. If we let $\mathbf{x}_s^{(i)} = [1, m_s^{(i)}]^T$ represent the $i$th note with fundamental pitch $m^{(i)}_s$ belonging to string $s$ , and let $\beta_s^{(i)}$ denote the log-inharmonicity of the $i$th note belonging to string $s$, we can solve
\begin{equation}
\label{lin-reg}
\mathbf{w}_s = \argmin_{\mathbf{w}}{\sum_{i=1}^{N_s}{(\beta^{(i)}_s - \mathbf{w}^T\mathbf{x}^{(i)}_s)^2}}
\end{equation}
which yields the weight vector $\mathbf{w}_s$ that minimizes the sum of squared error between the measured and predicted inharmonicities of the notes belonging to string $s$.
%\begin{figure}[!htbp] 
%\centering
%\includegraphics[scale=0.75]{traj-v-reg}
%\caption{Comparison of string inharmonicity characterization approaches for our recorded Fender Telecaster. Top: \textit{theoretical} trajectories. Note how each line begins precisely at the first marker of each string (i.e. the open-string note) and continues along a trajectory that ignores empirical inharmonicity estimates. String 1 most clearly shows this. Additionally, the trajectories for String 3 and String 4 are effectively co-linear and therefore indiscriminable. Bottom: regressions, or \textit{empirical} trajectories. Each regression was obtained by minimizing the bisquare weighted error of the residuals of the string, so the lines more closely follow the empirical inharmonicity scatterplot estimates.}
%\label{fig:traj-v-reg}
%\end{figure}

Occasional estimates from the inharmonicity measurement routine were outliers that deviated substantially from the linear trajectory model, so instead of the standard unweighted regression in~\eqref{lin-reg} we performed a bisquare weighted linear regression to approximate the log-inharmonicities. Bisquare weighting is a robust linear regression procedure that minimizes a \textit{weighted} sum of squares which de-emphasizes outliers \citep{matlab-robustfit}. This provided us with higher-quality regressions that were more robust to stray inharmonicity measurements.

To classify unknown notes, we imposed Gaussian probability distributions over the inharmonicity measurements of each string centered at their trajectories, and evaluated them at the inharmonicities of unseen notes to determine the most likely string from which it came. The means of the Gaussians are the log-inharmonicity values of points on the line, and the variances of the Gaussians are those of the residuals of the regressions, $\sigma_s^2$. In this manner, the probability distribution that characterized the inharmonicity trajectory $\mathbf{w}_s$ of string $s$ at the fundamental pitch $m_0^{(i)}$ of the $i$th note $\mathbf{x}^{(i)} = [1,m_0^{(i)}]^T$ was defined as the normal distribution $\mathcal{N}(\mu, \sigma^2)$, with mean $\mu = \mathbf{w}_s^T\mathbf{x}^{(i)}$ and variance $\sigma^2 = \sigma_s^2$. Now to classify the $n$th unseen note $\mathbf{x}^{(n)}$, we measured its log-inharmonicity $\beta^{(n)}$ and obtained the probability that this log-inharmonicity was observed given each string $s$ according to
\begin{equation}
P(\mathbf{x}^{(n)},\beta^{(n)} | s) = \mathcal{N}(\beta^{(n)} | \mathbf{w}_s^T\mathbf{x}^{(n)},\sigma_s^2),
\end{equation}
and returned the predicted string $\hat{s}^{(n)}$ that maximized this probability,
\begin{equation}
\hat{s}^{(n)} = \argmax_{s}P(\mathbf{x}^{(n)},\beta^{(n)} | s).
\label{eq:string-argmax}
\end{equation}
We also attempted classification using a decision function that selected the trajectory which minimized the residual instead of maximizing the probability, but we found that the probabilistic method performed better.

Then, we transformed the string classifier output into tablature notation. This is a trivial task because we know the tuning $\mathbf{t} = [m_1, m_2, m_3, m_4, m_5, m_6]^T$ of the unknown guitar, where $m_s$ is the MIDI pitch number of the open note on string $s$. Since we had an estimate of the MIDI pitch $m^{(n)}$ of the $n$th unknown note, so taking the difference between $m^{(n)}$ and the open pitch $m_s$ of its assigned string yielded the fret on which the note was played; each fret on a guitar increases the pitch of the string by one half-step, or equivalently the MIDI pitch number by one integer.

Lastly, we refined the fretboard estimates with plausibility filtering \citep{abesser2012}, in which we rejected and reassigned string decisions that were implausible given the constraints and assumptions of the data. If our systems assigned to a note a string on which the corresponding fretted position is negative, a mistake was made since frets cannot possibly be lower than 0 (the open-string). Similarly, if our system assigned to a note a string on which the corresponding fret is greater than 12, a mistake was made because our guitar recordings feature only frets 0-12. When either of these situations arose, we rejected the string classification decision and selected the next most probable string. If the succeeding string was also implausible, the process was iterated until all six strings were considered.

\subsection{Baseline Bayesian Classifier}
The hypothesis of our regression method was that exploitation of the linear trajectories of log-inharmonicities is helpful for transcription. To objectively evaluate this we developed a baseline classifier, which we simply called Bayesian classification, which \textit{does not} leveraged the inharmonicity trajectories and whose results served as a benchmark.

As before, we first measured the inharmonicities of guitar notes using median-adjustive-trajectories (MAT). Frame aggregation was performed using the same specifications discussed in Section~\ref{sub:inharmonicity-regression}. Next, we estimated the inharmonicity distribution of each fretboard position $f$. For each of the $F=78$ positions (13 notes $\times$ 6 strings), we calculated the median $\tilde{\beta}_f$ and variance $\sigma^2_f$ of its inharmonicities, and used these to parameterize a Gaussian probability density $\mathcal{N}_f(\tilde{\beta}_f,\sigma^2_f)$. We chose the median to lessen the influence of outliers.

We then classified unseen notes. We measured the inharmonicity $\beta^{(i)}$ of the $i$th unseen note $\mathbf{x}=[1,m_0^{(i)}]^T$ with fundamental MIDI pitch $m_0^{(i)}$ and evaluated the probability $P_f(\beta^{(i)} | f) = \mathcal{N}_f(\beta^{(i)} | \tilde{\beta}_f,\sigma^2_f)$ of it having been generated by the Gaussian distribution $\mathcal{N}_f$. We narrowed our search space $f \in \{1,2,3,...,F-1,F\}$ of possible fretboard positions by considering just the positions $f \in \{f_{m,1},f_{m,2},...\}$ that agree with the fundamental frequency of the unseen note. For standard-tuning, this is a maximum of only three positions. To classify a note, we selected the candidate fretboard position which maximized the likelihood of the measured inharmonicity of the note, just as in equation~\eqref{eq:string-argmax}:
\begin{equation}
\hat{f} = \argmax_{f\in\{f_{m,1},f_{m,2}...\}}P(\beta^{(i)} | f).
\label{eq:string-classification-mle}
\end{equation}

\section{Results}  
\subsection{RWC Transcription}
We evaluated our baseline and regression methods using a subset of the Real World Corpus (RWC) database \citep{goto2003}. We transcribed nine RWC guitars (three classical, three acoustic, and three electric) at three levels of context: guitar-specific, guitar-averaged, and guitar-independent. For guitar-specific trials, we trained and tested the system on the same guitar using three-fold cross-validation with test folds that were one-third of the guitar recordings. For guitar-averaged trials, we trained the system on all recordings of the two guitars in the same class as the test guitar, as well as a two-thirds training portion of the test guitar, and then evaluated on the remaining third of the test guitar recordings. For guitar-independent trials, we trained the system on two of the guitars in the same class as the test guitar, and tested on all recordings of the remaining one. We used error probabilities to quantify the transcription performance for each guitar.
%\twocolumn[
%\maketitle

Figure~\ref{fig:novel-methods-sig-comp} shows and compares the error probabilities of our two novel methods in all three contexts. We performed two-tailed McNemar test to assess the significance ($\alpha = 0.05$) of differences in transcription error rate. Transcripts of the $78$ notes $\times 12$ recordings $= 936$ string assignments of our two classifiers for each evaluation guitar ($468$ assignments for the fewer recordings of the electric guitars) along with their true labels were examined.

\begin{figure}[!htbp]
\centering
\includegraphics[scale=0.275]{novel-methods-sig-comp}
\caption{The method (Bayes or Regression), if any, that performs significantly better than its counterpart for each guitar is marked with a circle.}
\label{fig:novel-methods-sig-comp}
\end{figure}

Figure~\ref{fig:sig-comp-PCT} compares error rates and significance between our methods and the existing PCT method. We used paired-sample $t$-tests ($\alpha = 0.05$) for significance testing. Because we did not have access to the trial-by-trial transcription results of PCT, we approximated the standard deviation $\sigma_d$ of the distribution of the differences by the square root of the average of the variances of the methods $\sigma_d = \sqrt{(\sigma^2_1+\sigma^2_2)/2}$ according to the Bernoulli approximation, in which $\sigma_x^2 = p_x(1-p_x)$ and the success parameter $p_x$ is simply the difference of $1$ and the reported error probability of method $x$, i.e. $p_x = 1-\mu_x$. We calculated the $t$-score of each comparison according to $t = \mu_d/(\sigma_d/\sqrt{n})$, with $n= 78$ notes $\times 12$ recordings $=936$ classified instances over which the error probabilities were averaged ($n=468$ for the fewer recordings of the electric guitars). 

\begin{figure}[!h]
\centering
\includegraphics[scale=0.25]{sig-comp-PCT}
\caption{For each guitar in every trial, if either of our methods performed significantly differently than PCT we mark it with either an `O' or an `X'. The former denotes significantly lower error probability while the latter denotes significantly higher error probability. Note that electric guitar trials and ``Guitar-independent" trial contexts are omitted since comparisons with PCT in those cases are not available.}
\label{fig:sig-comp-PCT}
\end{figure}


\section{Discussion} 
\subsection{RWC Transcription}
Figure~\ref{fig:novel-methods-sig-comp} reveals that our two methods performed equally on eleven of the twenty-seven RWC classical, acoustic, and electric guitar recordings. In six other recordings the Bayesian baseline overtook the regression approach, but the latter outperformed the baseline in the remaining ten audio segments. Overall this suggests there is merit to leveraging the structure of log-inharmonicity trajectories for improved transcription.

Figure~\ref{fig:sig-comp-PCT} shows that PCT performed better than or just as well as both of our methods in eight of the twelve RWC classical and acoustic recordings. It was suspected that prior consideration of the inharmonicity of every fret would help our classifier learn a more reliable picture of the inharmonicity trajectory, but it appears this is not the case. The superior performance of PCT suggests that the theoretical inharmonicity trajectories are sufficient for transcription, at least for the ``guitar-specific'' and ``guitar-averaged'' trial contexts. It would be interesting to compare performance of PCT and our methods for electric guitars and for the ``guitar-independent'' trial context, but at the time of writing of this paper we were not sure whether the authors of PCT used the same subset of RWC electric guitar, and ``guitar-independent'' results were not reported in \citet{barbanchoi2012}.

We investigated the modest performance of our system by studying factors that could have compromised the inharmonicity estimation. One such pernicious factor was guitar string geometry. We recorded identical note plucks on personal guitars exhibiting an array of combinations of string age, intonation length, gauge size, and winding, and we observed that variations in the latter two affected our log-inharmonicity measurements by orders of magnitude between one-tenth and one. The degree of this variability is commensurate with that of our log-inharmonicity estimates of adjacent strings. The RWC database does not annotate string geometry parameters for any of its guitars, so it is possible this dimension interfered with the quality of reported transcription results among systems using this database. Future work should take care to control for this variable when possible.

\section{Summary} 
Tablature is a popular music notation for guitarists because it uniquely specifies fretboard positions for musical passages. Its manual annotation process, however, is tedious. Automatic transcription systems offer a solution to this difficulty. Inharmonicity, which affects the degree of upward skew of the partials of a note, is a key feature used in some successful systems \citep{barbanchoi2012}. We proposed to capitalize on the predictable log-inharmonicity trajectory of a string by characterizing it as a linear regression against its pitch, and we developed a baseline Bayesian classifier to contextualize the performance of this regression approach. 

Comparisons between our baseline and regression methods suggested that leveraging inharmonicity regressions is a worthwhile pursuit. Contrasting both of our methods against the existing PCT method, however, showed no significant improvement. We learned that, regardless of the degree to which it compromised the performance of this or other transcription systems, guitar string geometry is an important factor to consider when developing inharmonicity-based methods.

\bibliographystyle{jaes}

% Reference to bibliography file.
\bibliography{mybib}


\end{document}